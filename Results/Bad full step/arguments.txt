Training parameters:
env=Flight
iterations=2000
nstep=500
rolloutlimit=2500
discount=0.999
lr_policy=0.0001
lr_policy_gamma=0.4642
lr_policy_stepsize=50000.0
policy_weight_decay=1e-07
continuous=1
continuous_sigma=0.5
continuous_sigma_end=0.1
continuous_sigma_steps=2000
lr_critic=0.001
lr_critic_gamma=0.4642
lr_critic_stepsize=50000.0
critic_weight_decay=1e-07
critic_lag=10
valfreq=100
valcount=5
path_policy=None
path_critic=None
reward_normalization=0
network_save_interval=200
portSend=26000
portReceive=26001
difficulty=0.25
